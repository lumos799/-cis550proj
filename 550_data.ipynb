{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:39:16.424208Z",
     "start_time": "2024-11-15T04:38:58.741485Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install --upgrade accelerate\n",
    "!pip install evaluate\n",
    "!pip install datasets==2.14.0 pyarrow==12.0.0"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForTokenClassification\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "import datasets\n",
    "from datasets import load_dataset#, list_datasets\n",
    "from evaluate import evaluator\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import zipfile\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:39:22.268602Z",
     "start_time": "2024-11-15T04:39:18.050514Z"
    }
   },
   "id": "356945c58c83f6af",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_json_dataset(json_path):\n",
    "    try:\n",
    "        dataset = load_dataset('json', data_files=json_path, split='train')\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred while loading the dataset: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:39:23.794029Z",
     "start_time": "2024-11-15T04:39:23.789925Z"
    }
   },
   "id": "20f3499d4b3fca68",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, Features, Value\n",
    "\n",
    "# Step 1: Preprocess the JSON file\n",
    "def preprocess_json_file(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line)\n",
    "            # Convert 'attributes' field to a JSON string\n",
    "            if 'attributes' in data and isinstance(data['attributes'], dict):\n",
    "                data['attributes'] = json.dumps(data['attributes'])\n",
    "            elif 'attributes' in data and data['attributes'] is None:\n",
    "                data['attributes'] = 'null'\n",
    "            # Convert 'hours' field to a JSON string\n",
    "            if 'hours' in data and isinstance(data['hours'], dict):\n",
    "                data['hours'] = json.dumps(data['hours'])\n",
    "            elif 'hours' in data and data['hours'] is None:\n",
    "                data['hours'] = 'null'\n",
    "            json.dump(data, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "# Run the preprocessing function\n",
    "preprocess_json_file('yelp_academic_dataset_business.json', 'yelp_academic_dataset_business_processed.json')\n",
    "\n",
    "# Step 2: Define the features to specify data types\n",
    "features_business = Features({\n",
    "    'business_id': Value('string'),\n",
    "    'name': Value('string'),\n",
    "    'address': Value('string'),\n",
    "    'city': Value('string'),\n",
    "    'state': Value('string'),\n",
    "    'postal_code': Value('string'),\n",
    "    'latitude': Value('float32'),\n",
    "    'longitude': Value('float32'),\n",
    "    'stars': Value('float32'),\n",
    "    'review_count': Value('int32'),\n",
    "    'is_open': Value('int32'),\n",
    "    'attributes': Value('string'),\n",
    "    'categories': Value('string'),\n",
    "    'hours': Value('string'),\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:48:56.317561Z",
     "start_time": "2024-11-15T04:48:51.885897Z"
    }
   },
   "id": "5c1304092dcf1b3f",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "desired_fields = [\n",
    "    'user_id',\n",
    "    'name',\n",
    "    'review_count',\n",
    "    'yelping_since',\n",
    "    'useful',\n",
    "    'funny',\n",
    "    'cool',\n",
    "    'elite',\n",
    "    'friends'\n",
    "]\n",
    "\n",
    "def preprocess_user_json_file(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # 创建一个新的字典，只包含需要的字段\n",
    "            new_data = {}\n",
    "            for field in desired_fields:\n",
    "                if field in data:\n",
    "                    value = data[field]\n",
    "                    # 对 'friends' 和 'elite' 字段进行处理\n",
    "                    if field == 'friends':\n",
    "                        if value is None or value == '':\n",
    "                            new_data[field] = 'null'\n",
    "                        else:\n",
    "                            new_data[field] = str(value)\n",
    "                    elif field == 'elite':\n",
    "                        if value is None or value == '':\n",
    "                            new_data[field] = 'null'\n",
    "                        else:\n",
    "                            new_data[field] = str(value)\n",
    "                    else:\n",
    "                        new_data[field] = value\n",
    "                else:\n",
    "                    # 如果字段缺失，设置默认值\n",
    "                    if field in ['review_count', 'useful', 'funny', 'cool']:\n",
    "                        new_data[field] = 0\n",
    "                    else:\n",
    "                        new_data[field] = ''\n",
    "            json.dump(new_data, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "# 运行预处理函数\n",
    "preprocess_user_json_file('yelp_academic_dataset_user.json', 'yelp_academic_dataset_user_processed.json')\n",
    "\n",
    "# 步骤 2: 定义数据集的特征\n",
    "features_user = Features({\n",
    "    'user_id': Value('string'),\n",
    "    'name': Value('string'),\n",
    "    'review_count': Value('int64'),\n",
    "    'yelping_since': Value('string'),\n",
    "    'useful': Value('int64'),\n",
    "    'funny': Value('int64'),\n",
    "    'cool': Value('int64'),\n",
    "    'elite': Value('string'),\n",
    "    'friends': Value('string'),\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:55:05.329521Z",
     "start_time": "2024-11-15T04:54:19.988789Z"
    }
   },
   "id": "44728fa89b1b79e6",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 步骤 1：预处理 JSON 文件\n",
    "def preprocess_checkin_json_file(input_path, output_path):\n",
    "    desired_fields = ['business_id', 'date']\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line)\n",
    "            # 创建一个新的字典，只包含需要的字段\n",
    "            new_data = {}\n",
    "            for field in desired_fields:\n",
    "                value = data.get(field, '')\n",
    "                if value is None:\n",
    "                    value = ''\n",
    "                else:\n",
    "                    value = str(value).strip()\n",
    "                new_data[field] = value\n",
    "            json.dump(new_data, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "# 运行预处理函数\n",
    "preprocess_checkin_json_file('yelp_academic_dataset_checkin.json', 'yelp_academic_dataset_checkin_processed.json')\n",
    "\n",
    "# 步骤 2：定义数据集特征\n",
    "features_checkin = Features({\n",
    "    'business_id': Value('string'),\n",
    "    'date': Value('string'),\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:49:07.280456Z",
     "start_time": "2024-11-15T04:49:04.381907Z"
    }
   },
   "id": "382ccd6724052da1",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_review_json_file(input_path, output_path):\n",
    "    desired_fields = [\n",
    "        'review_id',\n",
    "        'user_id',\n",
    "        'business_id',\n",
    "        'stars',\n",
    "        'useful',\n",
    "        'funny',\n",
    "        'cool',\n",
    "        'text',\n",
    "        'date'\n",
    "    ]\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line)\n",
    "            # 创建一个新的字典，只包含需要的字段\n",
    "            new_data = {}\n",
    "            for field in desired_fields:\n",
    "                if field in data:\n",
    "                    value = data[field]\n",
    "                    if value is None:\n",
    "                        # 设置默认值\n",
    "                        if field in ['stars', 'useful', 'funny', 'cool']:\n",
    "                            value = 0\n",
    "                        else:\n",
    "                            value = ''\n",
    "                    new_data[field] = value\n",
    "                else:\n",
    "                    # 如果字段缺失，设置默认值\n",
    "                    if field in ['stars', 'useful', 'funny', 'cool']:\n",
    "                        new_data[field] = 0\n",
    "                    else:\n",
    "                        new_data[field] = ''\n",
    "            json.dump(new_data, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "# 运行预处理函数\n",
    "preprocess_review_json_file('yelp_academic_dataset_review.json', 'yelp_academic_dataset_review_processed.json')\n",
    "\n",
    "features_review = Features({\n",
    "    'review_id': Value('string'),\n",
    "    'user_id': Value('string'),\n",
    "    'business_id': Value('string'),\n",
    "    'stars': Value('int64'),\n",
    "    'useful': Value('int64'),\n",
    "    'funny': Value('int64'),\n",
    "    'cool': Value('int64'),\n",
    "    'text': Value('string'),\n",
    "    'date': Value('string'),\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:51:54.480420Z",
     "start_time": "2024-11-15T04:49:49.026903Z"
    }
   },
   "id": "b0e2f9874d394d50",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_tip_json_file(input_path, output_path):\n",
    "    desired_fields_tip = [\n",
    "        'user_id',\n",
    "        'business_id',\n",
    "        'text',\n",
    "        'date',\n",
    "        'compliment_count'\n",
    "    ]\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            data = json.loads(line)\n",
    "            # 创建一个新的字典，只包含需要的字段\n",
    "            new_data = {}\n",
    "            for field in desired_fields_tip:\n",
    "                if field in data:\n",
    "                    value = data[field]\n",
    "                    if value is None:\n",
    "                        # 设置默认值\n",
    "                        if field == 'compliment_count':\n",
    "                            value = 0\n",
    "                        else:\n",
    "                            value = ''\n",
    "                    new_data[field] = value\n",
    "                else:\n",
    "                    # 如果字段缺失，设置默认值\n",
    "                    if field == 'compliment_count':\n",
    "                        new_data[field] = 0\n",
    "                    else:\n",
    "                        new_data[field] = ''\n",
    "            json.dump(new_data, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "# 运行预处理函数\n",
    "preprocess_tip_json_file('yelp_academic_dataset_tip.json', 'yelp_academic_dataset_tip_processed.json')\n",
    "\n",
    "features_tip = Features({\n",
    "    'user_id': Value('string'),\n",
    "    'business_id': Value('string'),\n",
    "    'text': Value('string'),\n",
    "    'date': Value('string'),\n",
    "    'compliment_count': Value('int64'),\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:57:36.277326Z",
     "start_time": "2024-11-15T04:57:26.683138Z"
    }
   },
   "id": "755b3569dc89fc74",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_json_dataset_business(json_path):\n",
    "    try:\n",
    "        dataset = load_dataset('json', data_files=json_path, split='train', features=features_business)\n",
    "        print(\"Dataset loaded successfully.\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred while loading the dataset: {e}\")\n",
    "\n",
    "\n",
    "def load_user_dataset(json_path):\n",
    "    try:\n",
    "        dataset = load_dataset('json', data_files=json_path, split='train[:8%]', features=features_user)\n",
    "        desired_columns = ['user_id', 'name', 'review_count', 'yelping_since', 'useful']\n",
    "        dataset = dataset.select_columns(desired_columns)\n",
    "        print(\"数据集加载成功。\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise Exception(f\"加载数据集时发生错误: {e}\")\n",
    "\n",
    "\n",
    "def load_checkin_dataset(json_path):\n",
    "    try:\n",
    "        dataset = load_dataset(\n",
    "            'json',\n",
    "            data_files=json_path,\n",
    "            split='train',\n",
    "            features=features_checkin\n",
    "        )\n",
    "        print(\"数据集加载成功。\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"加载数据集时发生错误: {e}\")\n",
    "\n",
    "\n",
    "def load_review_dataset(json_path):\n",
    "    try:\n",
    "        dataset = load_dataset(\n",
    "            'json',\n",
    "            data_files=json_path,\n",
    "            split='train[:5%]',\n",
    "            features=features_review\n",
    "        )\n",
    "        print(\"数据集加载成功。\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"加载数据集时发生错误: {e}\")\n",
    "\n",
    "\n",
    "def load_tip_dataset(json_path):\n",
    "    try:\n",
    "        dataset = load_dataset(\n",
    "            'json',\n",
    "            data_files=json_path,\n",
    "            split='train[:20%]',\n",
    "            features=features_tip\n",
    "        )\n",
    "        print(\"数据集加载成功。\")\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"加载数据集时发生错误: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:33.041889Z",
     "start_time": "2024-11-15T04:59:33.033028Z"
    }
   },
   "id": "2f50246ff8d12f25",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['business_id', 'name', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars', 'review_count', 'is_open', 'attributes', 'categories', 'hours'],\n    num_rows: 150346\n})"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_business = load_json_dataset_business('yelp_academic_dataset_business_processed.json')\n",
    "dataset_business"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:33.694059Z",
     "start_time": "2024-11-15T04:59:33.618582Z"
    }
   },
   "id": "615262283635961f",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集加载成功。\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['user_id', 'name', 'review_count', 'yelping_since', 'useful'],\n    num_rows: 159032\n})"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_user = load_user_dataset('yelp_academic_dataset_user_processed.json')\n",
    "dataset_user"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:34.089503Z",
     "start_time": "2024-11-15T04:59:34.014438Z"
    }
   },
   "id": "d33877782e774f98",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集加载成功。\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['business_id', 'date'],\n    num_rows: 131930\n})"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_checkin = load_checkin_dataset('yelp_academic_dataset_checkin_processed.json')\n",
    "dataset_checkin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:34.624348Z",
     "start_time": "2024-11-15T04:59:34.554393Z"
    }
   },
   "id": "a9c7318f4b43dc80",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集加载成功。\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date'],\n    num_rows: 349514\n})"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_review = load_review_dataset('yelp_academic_dataset_review_processed.json')\n",
    "dataset_review"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:35.072557Z",
     "start_time": "2024-11-15T04:59:34.993177Z"
    }
   },
   "id": "f219ebcfae7cfadc",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集加载成功。\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['user_id', 'business_id', 'text', 'date', 'compliment_count'],\n    num_rows: 181783\n})"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tip = load_tip_dataset('yelp_academic_dataset_tip_processed.json')\n",
    "dataset_tip"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:35.625142Z",
     "start_time": "2024-11-15T04:59:35.548822Z"
    }
   },
   "id": "bd993b6471422457",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "user_ids = set(dataset_user['user_id'])\n",
    "business_ids = set(dataset_business['business_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:36.288208Z",
     "start_time": "2024-11-15T04:59:36.083288Z"
    }
   },
   "id": "2085ca407dc932db",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def filter_user(batch):\n",
    "    return [uid in user_ids for uid in batch['user_id']]\n",
    "\n",
    "def filter_business(batch):\n",
    "    return [bid in business_ids for bid in batch['business_id']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:37.232236Z",
     "start_time": "2024-11-15T04:59:37.227927Z"
    }
   },
   "id": "b0ced5b445406682",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Filter out invalid user_ids (num_proc=4):   0%|          | 0/349514 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "884eae2a984d4ea99af803a7ba7d07e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_reviews = dataset_review.filter(\n",
    "    filter_user,\n",
    "    batched=True,\n",
    "    batch_size=10000,\n",
    "    num_proc=4,\n",
    "    desc=\"Filter out invalid user_ids\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:38.628123Z",
     "start_time": "2024-11-15T04:59:37.680511Z"
    }
   },
   "id": "7550f5717d8d2789",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date'],\n    num_rows: 267871\n})"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reviews"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:39.251182Z",
     "start_time": "2024-11-15T04:59:39.247024Z"
    }
   },
   "id": "265f7623124018dc",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Filter out business_id (num_proc=4):   0%|          | 0/267871 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "117ad53ed355495ea1e9655d6f42a1f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_business_reviews(batch):\n",
    "    return [bid in business_ids for bid in batch['business_id']]\n",
    "\n",
    "filtered_reviews_business = filtered_reviews.filter(\n",
    "    filter_business_reviews,\n",
    "    batched=True,\n",
    "    batch_size=10000,\n",
    "    num_proc=4,\n",
    "    desc=\"Filter out business_id\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:42.738103Z",
     "start_time": "2024-11-15T04:59:39.911846Z"
    }
   },
   "id": "fa978eba66a8330d",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date'],\n    num_rows: 267871\n})"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reviews_business"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:43.476801Z",
     "start_time": "2024-11-15T04:59:43.472150Z"
    }
   },
   "id": "c7aff960f78082bd",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filtered_checkin = dataset_checkin.filter(\n",
    "    filter_business,\n",
    "    batched=True,\n",
    "    batch_size=10000,\n",
    "    num_proc=4,\n",
    "    desc=\"Filter out business_id\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:44.398604Z",
     "start_time": "2024-11-15T04:59:44.116806Z"
    }
   },
   "id": "b73a6d4f9125337f",
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['business_id', 'date'],\n    num_rows: 131930\n})"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_checkin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:45.121537Z",
     "start_time": "2024-11-15T04:59:45.118617Z"
    }
   },
   "id": "b4650a15ba037fc",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Filter out invalid user_ids (num_proc=4):   0%|          | 0/181783 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb59031d4a8349a4bed9541751d4a11b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_users_tip(batch):\n",
    "    return [uid in user_ids for uid in batch['user_id']]\n",
    "\n",
    "filtered_tip_user = dataset_tip.filter(\n",
    "    filter_user,\n",
    "    batched=True,\n",
    "    batch_size=10000,\n",
    "    num_proc=4,\n",
    "    desc=\"Filter out invalid user_ids\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:46.569565Z",
     "start_time": "2024-11-15T04:59:45.825787Z"
    }
   },
   "id": "865e1b061a96d1ca",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['user_id', 'business_id', 'text', 'date', 'compliment_count'],\n    num_rows: 175473\n})"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tip_user"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:47.539664Z",
     "start_time": "2024-11-15T04:59:47.534692Z"
    }
   },
   "id": "da021f79907f126e",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Filter out invalid user_ids (num_proc=4):   0%|          | 0/175473 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ccc20c13cb2471db32c755341c8ece7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_tip_user_business = filtered_tip_user.filter(\n",
    "    filter_business,\n",
    "    batched=True,\n",
    "    batch_size=10000,\n",
    "    num_proc=4,\n",
    "    desc=\"Filter out invalid user_ids\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:50.345602Z",
     "start_time": "2024-11-15T04:59:48.208838Z"
    }
   },
   "id": "60d02733ff4ebc65",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['user_id', 'business_id', 'text', 'date', 'compliment_count'],\n    num_rows: 175473\n})"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tip_user_business"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:50.891553Z",
     "start_time": "2024-11-15T04:59:50.887244Z"
    }
   },
   "id": "73e6c405c17eda03",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['user_id', 'name', 'review_count', 'yelping_since', 'useful'],\n    num_rows: 159032\n})"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_user"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T04:59:51.542878Z",
     "start_time": "2024-11-15T04:59:51.538291Z"
    }
   },
   "id": "bee3fe1137d4ea28",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/268 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "affed5de5ac14ec1aec6dc8fdd22399e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/160 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "420f225699ec465aa9a4589a5c20af29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/151 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07c4479ac68c41a0b0d3ba74c5e8e568"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/132 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1c7ea35119643a4a0f2ed7f9140b008"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Creating CSV from Arrow format:   0%|          | 0/176 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9630d9bd17fb4cb5b29a44b632888164"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "22955575"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 to_csv 方法保存数据集\n",
    "filtered_reviews_business.to_csv('yelp_dataset/yelp_reviews.csv', index=False)\n",
    "dataset_user.to_csv('yelp_dataset/yelp_user.csv', index=False)\n",
    "dataset_business.to_csv('yelp_dataset/yelp_business.csv', index=False)\n",
    "filtered_checkin.to_csv('yelp_dataset/yelp_checkin.csv', index=False)\n",
    "filtered_tip_user_business.to_csv('yelp_dataset/yelp_tip.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T05:00:46.451565Z",
     "start_time": "2024-11-15T05:00:32.074540Z"
    }
   },
   "id": "d20ff4a07ec61714",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                   user_id       name  review_count        yelping_since  \\\n0   qVc8ODYU5SZjKXVBgXdI7w     Walker           585  2007-01-25 16:47:26   \n1   j14WgRoU_-2ZE1aw1dXrJg     Daniel          4333  2009-01-25 04:35:42   \n2   2WnXYQFK0hXEoTxPtV2zvg      Steph           665  2008-07-25 10:41:00   \n3   SZDeASXq7o05mMNLshsdIA       Gwen           224  2005-11-29 04:38:33   \n4   hA5lMy-EnncsH4JoR-hFGQ      Karen            79  2007-01-05 19:40:59   \n..                     ...        ...           ...                  ...   \n95  8m2LgacB5VeP_1Mn5ZMC4w       Alan             4  2011-01-20 14:58:21   \n96  MvOXPiqRr9IjqVtwC5mUNA    Jessica           111  2010-08-01 20:00:52   \n97  PrJ37Ik9DxritxGPqI9ktw      David            85  2011-05-05 16:01:31   \n98  dHLL7SVGJw5uM6IEp_wb4Q  Constance           538  2010-07-30 22:23:15   \n99  UQFE3BT1rsIYrcDvu_XVow       Mike          1560  2005-07-22 23:17:54   \n\n    useful  \n0     7217  \n1    43091  \n2     2086  \n3      512  \n4       29  \n..     ...  \n95       1  \n96     286  \n97      75  \n98     694  \n99    2385  \n\n[100 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>name</th>\n      <th>review_count</th>\n      <th>yelping_since</th>\n      <th>useful</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>qVc8ODYU5SZjKXVBgXdI7w</td>\n      <td>Walker</td>\n      <td>585</td>\n      <td>2007-01-25 16:47:26</td>\n      <td>7217</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>j14WgRoU_-2ZE1aw1dXrJg</td>\n      <td>Daniel</td>\n      <td>4333</td>\n      <td>2009-01-25 04:35:42</td>\n      <td>43091</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2WnXYQFK0hXEoTxPtV2zvg</td>\n      <td>Steph</td>\n      <td>665</td>\n      <td>2008-07-25 10:41:00</td>\n      <td>2086</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SZDeASXq7o05mMNLshsdIA</td>\n      <td>Gwen</td>\n      <td>224</td>\n      <td>2005-11-29 04:38:33</td>\n      <td>512</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hA5lMy-EnncsH4JoR-hFGQ</td>\n      <td>Karen</td>\n      <td>79</td>\n      <td>2007-01-05 19:40:59</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>8m2LgacB5VeP_1Mn5ZMC4w</td>\n      <td>Alan</td>\n      <td>4</td>\n      <td>2011-01-20 14:58:21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>MvOXPiqRr9IjqVtwC5mUNA</td>\n      <td>Jessica</td>\n      <td>111</td>\n      <td>2010-08-01 20:00:52</td>\n      <td>286</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>PrJ37Ik9DxritxGPqI9ktw</td>\n      <td>David</td>\n      <td>85</td>\n      <td>2011-05-05 16:01:31</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>dHLL7SVGJw5uM6IEp_wb4Q</td>\n      <td>Constance</td>\n      <td>538</td>\n      <td>2010-07-30 22:23:15</td>\n      <td>694</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>UQFE3BT1rsIYrcDvu_XVow</td>\n      <td>Mike</td>\n      <td>1560</td>\n      <td>2005-07-22 23:17:54</td>\n      <td>2385</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义CSV文件路径\n",
    "csv_file_path = 'yelp_dataset/yelp_user.csv'\n",
    "\n",
    "# 读取CSV文件为DataFrame\n",
    "df_business = pd.read_csv(csv_file_path)\n",
    "\n",
    "df_business.head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-15T05:00:48.742681Z",
     "start_time": "2024-11-15T05:00:48.516755Z"
    }
   },
   "id": "5b320cd473a554ea",
   "execution_count": 79
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
